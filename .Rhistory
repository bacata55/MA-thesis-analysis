plot(log10(1:100), log10(topfeatures(mydfm, 100)),
xlab="log10(rank)", ylab="log10(frequency)", main="Top 100 Words")
# regression to check if slope is approx -1.0
regression <- lm(log10(topfeatures(mydfm, 100)) ~ log10(1:100))
abline(regression, col="red")
confint(regression)
topfeatures(mydfm, 20)
last_speech_text<-inaugCorpus$document$texts[57]
last_speech_text
collocations(last_speech_text)
collocations(last_speech_text, size=3)
colloc <- collocations(last_speech_text)
colloc
isStopwordList <- lapply(colloc$word1, `%in%`, stopwords("english"))
stopwordindex <- which(colloc$word1 %in% stopwords("english")| colloc$word2 %in% stopwords("english"))
colloc[-stopwordindex]  # collocations not containing stopwords
kwic(inaugCorpus, "terror", 3)
kwic(inaugCorpus, "angels", 3)
kwic(inaugCorpus, "slavery", 3)
x<-c(1,2,3)
y<-c(1,2,3)
##define the norm
norm_vec <- function(x) sqrt(sum(x^2))
norm_vec
norm_vec(x)
x %*% y / (norm_vec(x)*norm_vec(y))
a<-c(1,2,3)
b<-c(1,2,4000)
a %*% b / (norm_vec(a)*norm_vec(b))
last_speech_text<-inaugCorpus$document$texts[57]
first_speech_text<-inaugCorpus$document$texts[1]
inaug_dfm<-dfm(c(last_speech_text, first_speech_text),ignoredFeatures = stopwords("english"),    stem = TRUE)
tmp <- similarity(inaug_dfm, margin = "documents")
tmp
as.matrix(tmp)
inaug_dfm<-dfm(c(last_speech_text, first_speech_text))
#calculate similarity
tmp <- similarity(inaug_dfm, margin = "documents")
as.matrix(tmp)
inaug_dfm<-dfm(subset(inaugCorpus , Year > 1980),ignoredFeatures = stopwords("english"),    stem = TRUE)
tmp <- similarity(inaug_dfm, margin = "documents")
as.matrix(tmp)
similarity(inaug_dfm, "2009-Obama", n = 5, margin = "documents")
install.packages("zelig")
install.packages("Zelig")
install.packages("MatchIt")
install.packages("cem")
install.packages(c("curl", "NLP", "topicmodels"))
# Quant 2
# Leslie Huang
# PS 4
# Set up the workspace and libraries
setwd("/Users/lesliehuang/Dropbox/PS4")
library(foreign)
library(stargazer)
library(Zelig)
library(MatchIt)
library(cem)
# Import data (already cleaned)
trcdata <- read.dta("trckeep.dta")
install.packages("Zelig")
install.packages("MatchIt")
install.packages("MatchIt")
install.packags("cem")
install.packages("cem")
# Quant 2
# Leslie Huang
# PS 4
# Set up the workspace and libraries
setwd("/Users/lesliehuang/Dropbox/PS4")
library(foreign)
library(stargazer)
library(Zelig)
library(MatchIt)
library(cem)
# Import data (already cleaned)
trcdata <- read.dta("trckeep.dta")
library(quanteda)
library(quantedaData)
##load data
##load in data
data("iebudgetsCorpus")
df<-data.frame(iebudgetsCorpus$documents)
# Quant 2
# Leslie Huang
# PS 4
# Set up the workspace and libraries
setwd("/Users/lesliehuang/Dropbox/PS4")
library(foreign)
library(stargazer)
library(MatchIt)
# Import data (already cleaned)
trcdata <- read.dta("trckeep.dta")
setwd("/Users/lesliehuang/Dropbox/PS4/")
setwd("Users/lesliehuang/Dropbox/PS4")
tokens<-tokenize(iebudgetsCorpus, removePunct=TRUE)
class(df)
str(df)
class(tokens)
tokenz<-lapply(tokens,  length )
tokens
tokens[1]
tokenz[1]
library(MatchIt)
library(Zelig)
install.packages("graph")
typez<-lapply(lapply(tokens,  unique ), length)
typez[1]
library(quanteda)
library(quantedaData)
##load data
##load in data
data("iebudgetsCorpus")
df<-data.frame(iebudgetsCorpus$documents)
## Lexical diversity measures
# TTR
tokens<-tokenize(iebudgetsCorpus, removePunct=TRUE)
tokenz<-lapply(tokens,  length )
typez<-lapply(lapply(tokens,  unique ), length)
TTRz<-mapply("/",typez,tokenz,SIMPLIFY = FALSE)
TTRz
df$ttr<-unlist(TTRz)
str(df)
plot(df$ttr)
library("Zelig", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
remove.packages("Zelig")
remove.packages("cem")
df$year<-as.numeric(df$year)
aggregate(df$ttr, by=list(df$year), FUN=mean)
table(df$year)
aggregate(df$ttr, by=list(df$party), FUN=mean)
table(df$party)
?readability
df$read_FRE<-readability(df$texts, "Flesch")
aggregate(df$read_FRE, by=list(df$year), FUN=mean)
aggregate(df$read_FRE, by=list(df$party), FUN=mean)
readability(df$texts, "Fucks")
df$read_FRE<-readability(df$texts, "Flesch")
df$read_FRE
aggregate(df$read_FRE, by=list(df$year), FUN=mean)
aggregate(df$read_FRE, by=list(df$party), FUN=mean)
df$read_DC<-readability(df$texts, "Dale.Chall")
aggregate(df$read_DC, by=list(df$year), FUN=mean)
aggregate(df$read_DC, by=list(df$party), FUN=mean)
read<-readability(df$texts)
cor(read$Flesch, read$Dale.Chall)
TTRz
cor(read$Flesch, read$SMOG)
cor(read$Coleman.Liau, read$Dale.Chall)
cor(read$Fucks, read$Dale.Chall)
install.packages("dplyr")
install.packages("dplyr")
library(dplyr)
year_FRE<-data.frame(matrix(ncol = 5, nrow = 100))
df<-filter(df, party != "WUAG" & party != "SOC"  & party != "PBPA" )
party_FRE<-data.frame(matrix(ncol = 6, nrow = 100))
for(i in 1:100){
#sample 200
bootstrapped<-sample_n(df, 200, replace=TRUE)
bootstrapped$read_FRE<-readability(bootstrapped$texts, "Flesch")
#store results
year_FRE[i,]<-aggregate(bootstrapped$read_FRE, by=list(bootstrapped$year), FUN=mean)[,2]
party_FRE[i,]<-aggregate(bootstrapped$read_FRE, by=list(bootstrapped$party), FUN=mean)[,2]
}
library(quanteda)
for(i in 1:100){
#sample 200
bootstrapped<-sample_n(df, 200, replace=TRUE)
bootstrapped$read_FRE<-readability(bootstrapped$texts, "Flesch")
#store results
year_FRE[i,]<-aggregate(bootstrapped$read_FRE, by=list(bootstrapped$year), FUN=mean)[,2]
party_FRE[i,]<-aggregate(bootstrapped$read_FRE, by=list(bootstrapped$party), FUN=mean)[,2]
}
colnames(year_FRE)<-names(table(df$year))
colnames(party_FRE)<-names(table(df$party))
std <- function(x) sd(x)/sqrt(length(x))
year_ses<-apply(year_FRE, 2, std)
year_means<-apply(year_FRE, 2, mean)
party_ses<-apply(party_FRE, 2, std)
party_means<-apply(party_FRE, 2, mean)
###Plot results--year
coefs<-year_means
ses<-year_ses
y.axis <- c(1:5)
min <- min(coefs - 2*ses)
max <- max(coefs + 2*ses)
var.names <- colnames(year_FRE)
adjust <- 0
par(mar=c(2,8,2,2))
plot(coefs, y.axis, type = "p", axes = F, xlab = "", ylab = "", pch = 19, cex = .8,
xlim=c(min,max),ylim = c(.5,6.5), main = "")
rect(min,.5,max,1.5, col = c("grey97"), border="grey90", lty = 2)
rect(min,1.5,max,2.5, col = c("grey95"), border="grey90", lty = 2)
rect(min,2.5,max,3.5, col = c("grey97"), border="grey90", lty = 2)
rect(min,3.5,max,4.5, col = c("grey95"), border="grey90", lty = 2)
rect(min,4.5,max,5.5, col = c("grey97"), border="grey90", lty = 2)
#rect(min,5.5,max,6.5, col = c("grey97"), border="grey90", lty = 2)
axis(1, at = seq(min,max,(max-min)/10),
labels = c(round(min+0*((max-min)/10),3),
round(min+1*((max-min)/10),3),
round(min+2*((max-min)/10),3),
round(min+3*((max-min)/10),3),
round(min+4*((max-min)/10),3),
round(min+5*((max-min)/10),3),
round(min+6*((max-min)/10),3),
round(min+7*((max-min)/10),3),
round(min+8*((max-min)/10),3),
round(min+9*((max-min)/10),3),
round(max,3)),tick = T,cex.axis = .75, mgp = c(2,.7,0))
axis(2, at = y.axis, label = var.names, las = 1, tick = FALSE, cex.axis =.8)
abline(h = y.axis, lty = 2, lwd = .5, col = "white")
segments(coefs-qnorm(.975)*ses, y.axis+2*adjust, coefs+qnorm(.975)*ses, y.axis+2*adjust, lwd =  1)
segments(coefs-qnorm(.95)*ses, y.axis+2*adjust-.035, coefs-qnorm(.95)*ses, y.axis+2*adjust+.035, lwd = .9)
segments(coefs+qnorm(.95)*ses, y.axis+2*adjust-.035, coefs+qnorm(.95)*ses, y.axis+2*adjust+.035, lwd = .9)
points(coefs, y.axis+2*adjust,pch=21,cex=.8, bg="white")
library(ggplot2)
plot(coefs, y.axis, type = "p", axes = F, xlab = "", ylab = "", pch = 19, cex = .8,
xlim=c(min,max),ylim = c(.5,6.5), main = "")
rect(min,.5,max,1.5, col = c("grey97"), border="grey90", lty = 2)
rect(min,1.5,max,2.5, col = c("grey95"), border="grey90", lty = 2)
rect(min,2.5,max,3.5, col = c("grey97"), border="grey90", lty = 2)
rect(min,3.5,max,4.5, col = c("grey95"), border="grey90", lty = 2)
rect(min,4.5,max,5.5, col = c("grey97"), border="grey90", lty = 2)
#rect(min,5.5,max,6.5, col = c("grey97"), border="grey90", lty = 2)
axis(1, at = seq(min,max,(max-min)/10),
labels = c(round(min+0*((max-min)/10),3),
round(min+1*((max-min)/10),3),
round(min+2*((max-min)/10),3),
round(min+3*((max-min)/10),3),
round(min+4*((max-min)/10),3),
round(min+5*((max-min)/10),3),
round(min+6*((max-min)/10),3),
round(min+7*((max-min)/10),3),
round(min+8*((max-min)/10),3),
round(min+9*((max-min)/10),3),
round(max,3)),tick = T,cex.axis = .75, mgp = c(2,.7,0))
axis(2, at = y.axis, label = var.names, las = 1, tick = FALSE, cex.axis =.8)
abline(h = y.axis, lty = 2, lwd = .5, col = "white")
segments(coefs-qnorm(.975)*ses, y.axis+2*adjust, coefs+qnorm(.975)*ses, y.axis+2*adjust, lwd =  1)
segments(coefs-qnorm(.95)*ses, y.axis+2*adjust-.035, coefs-qnorm(.95)*ses, y.axis+2*adjust+.035, lwd = .9)
segments(coefs+qnorm(.95)*ses, y.axis+2*adjust-.035, coefs+qnorm(.95)*ses, y.axis+2*adjust+.035, lwd = .9)
points(coefs, y.axis+2*adjust,pch=21,cex=.8, bg="white")
table(df$year)
aggregate(df$read_FRE, by=list(df$year), FUN=mean)
coefs<-party_means
ses<-party_ses
y.axis <- c(1:6)
min <- min(coefs - 2*ses)
max <- max(coefs + 2*ses)
var.names <- colnames(party_FRE)
adjust <- 0
par(mar=c(2,8,2,2))
plot(coefs, y.axis, type = "p", axes = F, xlab = "", ylab = "", pch = 19, cex = .8,
xlim=c(min,max),ylim = c(.5,6.5), main = "")
rect(min,.5,max,1.5, col = c("grey97"), border="grey90", lty = 2)
rect(min,1.5,max,2.5, col = c("grey95"), border="grey90", lty = 2)
rect(min,2.5,max,3.5, col = c("grey97"), border="grey90", lty = 2)
rect(min,3.5,max,4.5, col = c("grey95"), border="grey90", lty = 2)
rect(min,4.5,max,5.5, col = c("grey97"), border="grey90", lty = 2)
rect(min,5.5,max,6.5, col = c("grey97"), border="grey90", lty = 2)
axis(1, at = seq(min,max,(max-min)/10),
labels = c(round(min+0*((max-min)/10),3),
round(min+1*((max-min)/10),3),
round(min+2*((max-min)/10),3),
round(min+3*((max-min)/10),3),
round(min+4*((max-min)/10),3),
round(min+5*((max-min)/10),3),
round(min+6*((max-min)/10),3),
round(min+7*((max-min)/10),3),
round(min+8*((max-min)/10),3),
round(min+9*((max-min)/10),3),
round(max,3)),tick = T,cex.axis = .75, mgp = c(2,.7,0))
axis(2, at = y.axis, label = var.names, las = 1, tick = FALSE, cex.axis =.8)
abline(h = y.axis, lty = 2, lwd = .5, col = "white")
segments(coefs-qnorm(.975)*ses, y.axis+2*adjust, coefs+qnorm(.975)*ses, y.axis+2*adjust, lwd =  1)
segments(coefs-qnorm(.95)*ses, y.axis+2*adjust-.035, coefs-qnorm(.95)*ses, y.axis+2*adjust+.035, lwd = .9)
segments(coefs+qnorm(.95)*ses, y.axis+2*adjust-.035, coefs+qnorm(.95)*ses, y.axis+2*adjust+.035, lwd = .9)
points(coefs, y.axis+2*adjust,pch=21,cex=.8, bg="white")
##real world data
table(df$party)
aggregate(df$read_FRE, by=list(df$party), FUN=mean)
df$
browseVignettes(package = "dplyr")
0.1*9
# Leslie Huang
# LIWC analysis of FARC communiques
rm(list=ls())
setwd("/Users/lesliehuang/Dropbox/MA-thesis-analysis/")
libraries <- c("foreign", "utils", "stargazer", "dplyr", "devtools", "quanteda", "quantedaData", "ggplot2", "stringr", "LIWCalike", "topicmodels", "lda", "stm", "LDAvis", "austin")
lapply(libraries, require, character.only=TRUE)
# get LIWC dict
spanish_dict <- dictionary(file = "../LIWC/Spanish_LIWC2007_Dictionary.dic", format = "LIWC")
# some major dates for plotting
major_violence <- as.Date(c("7/20/13", "1/16/13", "7/29/14", "11/16/14", "4/15/15", "5/31/15", "6/15/15", "6/22/15"), "%m/%d/%y")
major_agree <- as.Date(c("8/26/12", "5/26/13", "11/6/13", "5/16/14", "3/7/15", "6/2/15", "9/23/15"), "%m/%d/%y")
# cf_start <- as.Date(c("11/20/12", "12/15/13", "5/16/14", "12/20/14", "7/20/15"), "%m/%d/%y")
# cf_end <- as.Date(c("1/20/13", "1/15/14", "5/28/14", "5/22/15", "1/1/16"), "%m/%d/%y")
ceasefires <- data.frame(start = as.Date(c("11/20/12", "12/15/13", "5/16/14", "12/20/14", "7/20/15"), "%m/%d/%y"), end = as.Date(c("1/20/13", "1/15/14", "5/28/14", "5/22/15", "1/1/16"), "%m/%d/%y"))
# dataframe of all dates
dates <- rbind(data.frame(date = major_violence, group = "major_viol"), data.frame(date = major_agree, group = "major_agree"))
####################################################################################
# import FARC communiques
FARC <- read.csv("../MA-datasets/FARC_communiques.csv", stringsAsFactors = FALSE)
# metadata: get date
FARC_meta <- select(FARC, date)
FARC_dates <- as.Date(FARC_meta[[1]], "%Y-%m-%d")
# create corpus
FARC_corp <- corpus(FARC$text, docvars = FARC_meta)
FARC_dfm <- dfm(FARC_corp, language = "spanish", stem = TRUE, ignoredFeatures = stopwords("spanish"))
# run LIWC
liwc_FARC <- liwcalike(FARC$text, spanish_dict)
# neg and pos emotion
FARC_neg <- data.frame(cbind(FARC_dates, as.numeric(liwc_FARC$EmoNeg)))
FARC_neg$FARC_dates <- as.Date(FARC_dates, origin = "1970-01-01")
FARC_pos <- data.frame(cbind(FARC_dates, as.numeric(liwc_FARC$EmoNeg)))
FARC_pos$FARC_dates <- as.Date(FARC_dates, origin = "1970-01-01")
####################################################################################
# do the same for joint communiques
joint <- read.csv("../MA-datasets/jointstatements.csv", stringsAsFactors = FALSE)
# delete some empty documents
joint <- filter(joint, text != "")
joint <- slice(joint, -19)
# get metadata: dates
joint_meta <- select(joint, date)
joint_dates <- as.Date(joint_meta[[1]], "%Y-%m-%d")
# run LIWC
liwc_joint <- liwcalike(joint$text, spanish_dict)
# get neg and pos emotion
joint_neg <- as.data.frame(cbind(joint_dates, as.numeric(liwc_joint$EmoNeg)))
joint_neg$joint_dates <- as.Date(joint_neg$joint_dates, origin = "1970-01-01")
joint_pos <- as.data.frame(cbind(joint_dates, as.numeric(liwc_joint$EmoPos)))
joint_pos$joint_dates <- as.Date(joint_neg$joint_dates, origin = "1970-01-01")
####################################################################################
# get govt statements
govt <- read.csv("govtstatements.csv", stringsAsFactors = FALSE)
govt_meta <- select(govt, date)
govt_dates <- as.Date(govt_meta[[1]], "%Y-%m-%d")
# run LIWC
liwc_govt <- liwcalike(govt$text, spanish_dict)
govt_neg <- as.data.frame(cbind(govt_dates, as.numeric(liwc_govt$EmoNeg)))
govt_neg$govt_dates <- as.Date(govt_neg$govt_dates, origin = "1970-01-01")
govt_pos <- as.data.frame(cbind(govt_dates, as.numeric(liwc_govt$EmoPos)))
govt_pos$govt_dates <- as.Date(govt_pos$govt_dates, origin = "1970-01-01")
####################################################################################
# let's graph negative emotion
# plot(FARC_dates, FARC_neg$V2, xlim = c(as.Date("2011-01-01", "%Y-%m-%d"), as.Date("2016-06-01", "%Y-%m-%d")))
# Neg emotion: base graph
base_neg = ggplot() +
geom_line(data = FARC_neg, aes(x = FARC_dates, y = V2, color = "FARC statement")) +
geom_jitter() +
#  geom_point(data = joint_neg, aes(x = joint_dates, y = V2, color = "Joint statement")) +
geom_line(data = joint_neg, aes(x = joint_dates, y = V2, color = "Joint statement")) +
geom_line(data = govt_neg, aes(x = govt_dates, y = V2, color = "Govt statement")) +
labs(
x = "Date",
y = "Percent Neg Emotion",
color = "Legend") +
scale_x_date(date_minor_breaks = "1 month",
limits = c(as.Date("2012-06-01", "%Y-%m-%d"), NA))
# Neg emotion and major agreements/violence
neg_major <- base_neg +
ggtitle("Major Events and Percent Negative Emotion Words in Statements") +
geom_vline(data = filter(dates, group == "major_agree"), mapping = aes(xintercept = as.numeric(date), color = "Major agreement"), linetype = 2) +
geom_vline(data = filter(dates, group == "major_viol"), mapping = aes(xintercept = as.numeric(date), color = "Major violence"), linetype = 1)
# Neg emotion and ceasefire dates
neg_cf <- base_neg +
ggtitle("Ceasefires and Percent Negative Emotion Words in Statements") +
geom_rect(aes(xmin=cf_start[1], xmax=cf_end[1], ymin=-Inf, ymax=Inf), fill = "yellow", linetype = 0, alpha = 0.3) +
geom_rect(aes(xmin=cf_start[2], xmax=cf_end[2], ymin=-Inf, ymax=Inf), fill = "yellow", linetype = 0, alpha = 0.3) +
geom_rect(aes(xmin=cf_start[3], xmax=cf_end[3], ymin=-Inf, ymax=Inf), fill = "yellow", linetype = 0, alpha = 0.3) +
geom_rect(aes(xmin=cf_start[4], xmax=cf_end[4], ymin=-Inf, ymax=Inf), fill = "yellow", linetype = 0, alpha = 0.3) +
geom_rect(aes(xmin=cf_start[5], xmax=cf_end[5], ymin=-Inf, ymax=Inf), fill = "yellow", linetype = 0, alpha = 0.3)
####################################################################################
# Pos emotion: base graph
base_pos = ggplot() +
geom_line(data = FARC_pos, aes(x = FARC_dates, y = V2, color = "FARC statement")) +
geom_jitter() +
#  geom_point(data = joint_pos, aes(x = joint_dates, y = V2, color = "Joint statement")) +
geom_line(data = joint_pos, aes(x = joint_dates, y = V2, color = "Joint statement")) +
geom_line(data = govt_pos, aes(x = govt_dates, y = V2, color = "Govt statement")) +
labs(
x = "Date",
y = "Percent Positive Emotion",
color = "Legend") +
scale_x_date(date_minor_breaks = "1 month",
limits = c(as.Date("2012-06-01", "%Y-%m-%d"), NA))
# pos emotion and major agreements
pos_major <- base_pos +
ggtitle("Major Events and Percent Positive Emotion Words in Statements") +
geom_vline(data = filter(dates, group == "major_agree"), mapping = aes(xintercept = as.numeric(date), color = "Major agreement"), linetype = 2) +
geom_vline(data = filter(dates, group == "major_viol"), mapping = aes(xintercept = as.numeric(date), color = "Major violence"), linetype = 1)
# pos emotion and ceasefires
pos_cf <- base_pos +
ggtitle("Ceasefires and Percent Positive Emotion Words in Statements") +
geom_rect(aes(xmin=cf_start[1], xmax=cf_end[1], ymin=-Inf, ymax=Inf), fill = "yellow", linetype = 0, alpha = 0.3) +
geom_rect(aes(xmin=cf_start[2], xmax=cf_end[2], ymin=-Inf, ymax=Inf), fill = "yellow", linetype = 0, alpha = 0.3) +
geom_rect(aes(xmin=cf_start[3], xmax=cf_end[3], ymin=-Inf, ymax=Inf), fill = "yellow", linetype = 0, alpha = 0.3) +
geom_rect(aes(xmin=cf_start[4], xmax=cf_end[4], ymin=-Inf, ymax=Inf), fill = "yellow", linetype = 0, alpha = 0.3) +
geom_rect(aes(xmin=cf_start[5], xmax=cf_end[5], ymin=-Inf, ymax=Inf), fill = "yellow", linetype = 0, alpha = 0.3)
####################################################################################
# let's graph 3rd person plural pronouns from FARC -- indicator of extremism
FARC_ellos <- data.frame(ell = as.numeric(liwc_FARC$Ellos), date = FARC_dates)
joint_ellos <- data.frame(ell = as.numeric(liwc_joint$Ellos), date = joint_dates)
base_ellos = ggplot() +
geom_line(data = FARC_ellos, aes(x = date, y = ell, color = "FARC statement")) +
geom_jitter() +
# geom_point(data = joint_neg, aes(x = joint_dates, y = V2, color = "Joint statement")) +
geom_line(data = joint_ellos, aes(x = date, y = ell, color = "Joint statement")) +
# geom_line(data = govt_neg, aes(x = govt_dates, y = V2, color = "Govt statement")) +
labs(
x = "Date",
y = "Percent 3rd Person Pl Pronoun",
color = "Legend") +
scale_x_date(date_minor_breaks = "1 month",
limits = c(as.Date("2012-06-01", "%Y-%m-%d"), NA))
# add major agreements and ceasefires
ellos_major <- base_ellos +
ggtitle("Major Events and Use of 3rd Person Pl. Pronoun") +
geom_vline(data = filter(dates, group == "major_agree"), mapping = aes(xintercept = as.numeric(date), color = "Major agreement"), linetype = 2) +
geom_vline(data = filter(dates, group == "major_viol"), mapping = aes(xintercept = as.numeric(date), color = "Major violence"), linetype = 1)
# run all the graphs
base_neg
base_pos
base_ellos
neg_cf
neg_major
pos_cf
pos_major
ellos_major
###############################################
# topic model
trim_FARC <- quanteda::trim(FARC_dfm, minCount = 30, minDoc = 10)
TM <- LDA(trim_FARC, 30, method = "Gibbs", control = list(burnin = 3, thin = 30, iter = 30, seed = 1234))
top10words <- get_terms(TM, k = 10)
doc_topics <- TM@gamma
LDApost <- posterior(TM)
jsonLDA <- createJSON(phi = LDApost$terms,
theta = LDApost$topics,
doc.length = ntoken(trim_FARC),
vocab = features(trim_FARC),
term.frequency = colSums(trim_FARC))
serVis(jsonLDA, out.dir = "visCollLDA", open.browser = TRUE)
lowess_F_neg <- lowess(FARC_dates, y = FARC_neg$V2, f = 2/3, iter = 3, delta = 0.01 * diff(range(FARC_dates)))
lowess_F_neg$x <- as.Date(FARC_dates, origin = "1970-01-01")
base_neg = ggplot() +
geom_line(data = lowess_F_neg, aes(x = FARC_dates, y = V2, color = "FARC statement")) +
geom_jitter() +
#  geom_point(data = joint_neg, aes(x = joint_dates, y = V2, color = "Joint statement")) +
geom_line(data = joint_neg, aes(x = joint_dates, y = V2, color = "Joint statement")) +
geom_line(data = govt_neg, aes(x = govt_dates, y = V2, color = "Govt statement")) +
labs(
x = "Date",
y = "Percent Neg Emotion",
color = "Legend") +
scale_x_date(date_minor_breaks = "1 month",
limits = c(as.Date("2012-06-01", "%Y-%m-%d"), NA))
lowess_F_neg <- unlist(lowess_F_neg)
# Neg emotion: base graph
base_neg = ggplot() +
geom_line(data = lowess_F_neg, aes(x = FARC_dates, y = V2, color = "FARC statement")) +
geom_jitter() +
#  geom_point(data = joint_neg, aes(x = joint_dates, y = V2, color = "Joint statement")) +
geom_line(data = joint_neg, aes(x = joint_dates, y = V2, color = "Joint statement")) +
geom_line(data = govt_neg, aes(x = govt_dates, y = V2, color = "Govt statement")) +
labs(
x = "Date",
y = "Percent Neg Emotion",
color = "Legend") +
scale_x_date(date_minor_breaks = "1 month",
limits = c(as.Date("2012-06-01", "%Y-%m-%d"), NA))
View(lowess_F_neg)
lowess_F_neg[[1]]
FARC_dates[[1]]
FARC_neg$FARC_dates[1]
lowess_F_neg <- lowess(FARC_dates, y = FARC_neg$V2, f = 2/3, iter = 3, delta = 0.01 * diff(range(FARC_dates)))
lowess_F_neg <- unlist(lowess_F_neg)
class(lowess_F_neg)
class(lowess_F_neg[[1]])
class(lowess_F_neg[1,1)
class(lowess_F_neg[1,1])
class(lowess_F_neg[2])
lowess_F_neg[1]
lowess_F_neg[2]
lowess_F_neg
class(lowess_F_neg)
lowess_F_neg <- lowess(FARC_dates, y = FARC_neg$V2, f = 2/3, iter = 3, delta = 0.01 * diff(range(FARC_dates)))
class(lowess_F_neg)
lowess_F_neg <- unlist(lowess_F_neg)
lowess_F_neg <- lowess(FARC_dates, y = FARC_neg$V2, f = 2/3, iter = 3, delta = 0.01 * diff(range(FARC_dates)))
lowess_F_neg <- data.frame(unlist(lowess_F_neg))
lowess_F_neg
lowess_F_neg <- lowess(FARC_dates, y = FARC_neg$V2, f = 2/3, iter = 3, delta = 0.01 * diff(range(FARC_dates)))
lowess_F_neg
lowess_F_neg$y
class(lowess_F_neg$y)
lowess_F_neg$y[1]
lowess_F_neg$y[12]
FARC_neg$V2
FARC_neg$V2 <- lowess_F_neg$y
base_neg = ggplot() +
geom_line(data = FARC_neg, aes(x = FARC_dates, y = V2, color = "FARC statement")) +
geom_jitter() +
#  geom_point(data = joint_neg, aes(x = joint_dates, y = V2, color = "Joint statement")) +
geom_line(data = joint_neg, aes(x = joint_dates, y = V2, color = "Joint statement")) +
geom_line(data = govt_neg, aes(x = govt_dates, y = V2, color = "Govt statement")) +
labs(
x = "Date",
y = "Percent Neg Emotion",
color = "Legend") +
scale_x_date(date_minor_breaks = "1 month",
limits = c(as.Date("2012-06-01", "%Y-%m-%d"), NA))
base_neg
